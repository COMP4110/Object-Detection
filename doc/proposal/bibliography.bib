%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Mitchell Metcalfe at 2015-03-23 11:21:01 +1100 


%% Saved with string encoding Unicode (UTF-8) 



@article{Yuan2015,
	Abstract = {Abstract The detection of circles from digital images is very important to shape recognition. In this paper, we propose and analyze a novel method, based on power histograms to detect circles in an image. The key idea is to transform an image into several power histograms that are computed from the pairwise distance products referring to the rays emanated from some reference points on the image. According to the circle power theorem, the edge pixels on a circle share the same circle powers with respect to an arbitrary point on the image. The peaks in the power histograms provide strong evidence for the existence of real circles. A multi-reference cross validation among various peaks can systematically remove randomness and eliminate false detections. Experimental results over several synthetic as well as natural images with varying ranges of complexity validate the efficacy of the proposed method in terms of its accuracy, simplicity, and robustness. },
	Author = {Bodi Yuan and Min Liu},
	Doi = {http://dx.doi.org/10.1016/j.patcog.2015.01.003},
	Issn = {0031-3203},
	Journal = {Pattern Recognition},
	Keywords = {Image processing},
	Number = {0},
	Pages = {-},
	Title = {Power histogram for circle detection on images},
	Url = {http://www.sciencedirect.com/science/article/pii/S0031320315000060},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0031320315000060},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.patcog.2015.01.003}}

@article{Pan2011,
	Abstract = {Accurate and efficient detection of circular objects in images is a challenging computer vision problem. Existing circular object detection methods can be broadly classified into two categories: voting based and maximum likelihood estimation (MLE) based. The former is robust to noise, however its computational complexity and memory requirement are high. On the other hand, MLE based methods (e.g., robust least squares fitting) are more computationally efficient but sensitive to noise, and can not detect multiple circles. This letter proposes Probabilistic Pairwise Voting (PPV), a fast and robust algorithm for circular object detection based on an extension of Hough Transform. The main contributions are threefold. 1) We formulate the problem of circular object detection as finding the intersection of lines in the three dimensional parameter space (i.e., center and radius of the circle). 2) We propose a probabilistic pairwise voting scheme to robustly discover circular objects under occlusion, image noise and moderate shape deformations. 3) We use a mode-finding algorithm to efficiently find multiple circular objects. We demonstrate the benefits of our approach on two real-world problems: 1) detecting circular objects in natural images, and 2) localizing iris in face images.},
	Author = {Lili Pan and Wen-Sheng Chu and Saragih, J.M. and De la Torre, F. and Mei Xie},
	Doi = {10.1109/LSP.2011.2166956},
	Issn = {1070-9908},
	Journal = {Signal Processing Letters, IEEE},
	Keywords = {Hough transforms;computational complexity;computer vision;image denoising;maximum likelihood estimation;object detection;Hough transform;MLE based methods;circular object detection methods;computational complexity;computer vision problem;fast circular object detection;image denoising;maximum likelihood estimation;mode-finding algorithm;probabilistic pairwise voting;robust circular object detection;shape deformations;Accuracy;Face;Image edge detection;Noise;Object detection;Robustness;Shape;Circular Hough Transform;Circular object detection;iris localization},
	Month = {Nov},
	Number = {11},
	Pages = {639-642},
	Title = {Fast and Robust Circular Object Detection With Probabilistic Pairwise Voting},
	Volume = {18},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LSP.2011.2166956}}

@incollection{Fusek2014,
	Abstract = {In this paper, we propose an efficient and interesting way how
	to encode the shape of the objects. A lot of state-of-the art descriptors
	(e.g. HOG, Haar, LBP) are based on the fact that the shape of the objects
	can be described by brightness differences inside the image. It means that
	the descriptors encode the gradient or intensity differences inside the
	image (i.e. edges). In the cases that the edges are very thin, the edge
	information can be difficult to obtain and the dimensionally of feature
	vector (without the method for reduction) is typically large and contains
	redundant information. These ills are motivation for the proposed method
	in that the edges need not be hit directly; the input brightness function
	is transformed using the appropriate image distance function. After this
	transformation, the values of distance function inside objects and
	backgrounds are different and the values can be used for description of
	object appearance. We demonstrate the properties of the method for the
	case of solving the problem of face detection using the classical sliding
	window technique.},
	Author = {Fusek, Radovan and Sojka, Eduard},
	Booktitle = {Pattern Recognition},
	Doi = {10.1007/978-3-319-11752-2_40},
	Editor = {Jiang, Xiaoyi and Hornegger, Joachim and Koch, Reinhard},
	Isbn = {978-3-319-11751-5},
	Language = {English},
	Pages = {488-498},
	Publisher = {Springer International Publishing},
	Series = {Lecture Notes in Computer Science},
	Title = {Distance-Based Descriptors and Their Application in the Task of Object Detection},
	Url = {http://dx.doi.org/10.1007/978-3-319-11752-2_40},
	Volume = {8753},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-319-11752-2_40}}

@inproceedings{schulz2007ball,
	Author = {Schulz, Hannes and Strasdat, Hauke and Behnke, Sven},
	Booktitle = {Proc. of Second Workshop on Humanoid Soccer Robots, Pittsburgh},
	Title = {A ball is not just orange: Using color and luminance to classify regions of interest},
	Year = {2007}}

@article{nillius2008shading,
	Address = {Los Alamitos, CA, USA},
	Author = {Peter Nillius and Josephine Sullivan and Antonis Argyros},
	Doi = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2008.4587773},
	Isbn = {978-1-4244-2242-5},
	Journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
	Pages = {1-8},
	Publisher = {IEEE Computer Society},
	Title = {Shading models for illumination and reflectance invariant shape detectors},
	Volume = {0},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2008.4587773}}

@inproceedings{masselli2013haar,
	Abstract = {In this paper, we present a robust method for detecting multiple balls without using color information. The method builds upon the boosted Haar classifier approach introduced by Viola et al. [11] and is applied onto an image from a catadioptric camera without performing rectification of the image. We compare the method with one based on a classical color segmentation approach. Originally both methods have been developed for the participation on the 2012 ``SICK robot day'', an international robotics competition. The task was to collect balls with a robot and put them into dedicated perches within a certain amount of time. Both methods showed to be robust during the competition. Our team placed second out of fifteen contenders.},
	Author = {Masselli, A. and Hanten, R. and Zell, A.},
	Booktitle = {Mobile Robots (ECMR), 2013 European Conference on},
	Doi = {10.1109/ECMR.2013.6698867},
	Keywords = {Hough transforms;cameras;image classification;image colour analysis;mobile robots;object detection;robot vision;SICK robot day;ball collection;boosted Haar classifier approach;catadioptric camera;color information;international robotics competition;mobile robot;robust real-time multiple ball detection;Cameras;Detectors;Image color analysis;Image segmentation;Mobile robots;Training},
	Month = {Sept},
	Pages = {355-360},
	Title = {Robust real-time detection of multiple balls on a mobile robot},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ECMR.2013.6698867}}

@article{viola2001robust,
	Author = {Viola, Paul and Jones, Michael},
	Journal = {International Journal of Computer Vision},
	Pages = {34--47},
	Title = {Robust real-time object detection},
	Volume = {4},
	Year = {2001}}

@inproceedings{mitri2004fast,
	Author = {Mitri, Sara and Perv{\"o}lz, Kai and Surmann, Hartmut and N{\"u}chter, Andreas},
	Booktitle = {Proceedings of the IEEE International Conference Mechatronics and Robotics},
	Pages = {900--905},
	Title = {Fast color-independent ball detection for mobile robots},
	Year = {2004}}

@article{li2013survey,
	Author = {Li, Xun and Lu, Huimin and Xiong, Dan and Zhang, Hui and Zheng, Zhiqiang},
	Journal = {International Journal of Advanced Robotic Systems},
	Title = {A Survey on Visual Perception for RoboCup MSL Soccer Robots},
	Volume = {1},
	Year = {2013}}

@article{Treptow2004filter,
	Abstract = {Objects in the RoboCup scenario (soccer playing robots) are identified by their unique color. These visual cues will be removed in the near future so that new vision algorithms are needed to cope with this. In this paper we present a method for detecting and tracking the ball in a RoboCup scenario without the need for color information. We use Haar-like features trained by an adaboost algorithm to get a colorless representation of the ball. Tracking is performed by a particle filter. It is shown that our algorithm is able to track the ball in real-time with 25&#xa0;fps even in a cluttered environment. },
	Author = {Andr{\'e} Treptow and Andreas Zell},
	Doi = {http://dx.doi.org/10.1016/j.robot.2004.05.005},
	Issn = {0921-8890},
	Journal = {Robotics and Autonomous Systems},
	Keywords = {Robot soccer},
	Note = {European Conference on Mobile Robots (ECMR '03)},
	Number = {1},
	Pages = {41 - 48},
	Title = {Real-time object tracking for soccer-robots without color information},
	Url = {http://www.sciencedirect.com/science/article/pii/S0921889004000752},
	Volume = {48},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0921889004000752},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.robot.2004.05.005}}

@article{zhang2013novel,
	Author = {Zhang, Hui and Lu, Huimin and Dong, Peng and Xiong, Dan and Zheng, Zhiqiang},
	Journal = {International Journal of Advanced Robotic Systems},
	Publisher = {INTECH-OPEN ACCESS PUBLISHER JANEZA TRDINE 9, RIJEKA, 51000, CROATIA},
	Title = {A Novel Generic Ball Recognition Algorithm Based on Omnidirectional Vision for Soccer Robots},
	Volume = {10},
	Year = {2013}}

@inproceedings{Lienhart2002extended,
	Abstract = {Recently Viola et al. [2001] have introduced a rapid object detection. scheme based on a boosted cascade of simple feature classifiers. In this paper we introduce a novel set of rotated Haar-like features. These novel features significantly enrich the simple features of Viola et al. and can also be calculated efficiently. With these new rotated features our sample face detector shows off on average a 10% lower false alarm rate at a given hit rate. We also present a novel post optimization procedure for a given boosted cascade improving on average the false alarm rate further by 12.5%.},
	Author = {Lienhart, R. and Maydt, J.},
	Booktitle = {Image Processing. 2002. Proceedings. 2002 International Conference on},
	Doi = {10.1109/ICIP.2002.1038171},
	Issn = {1522-4880},
	Keywords = {Haar transforms;face recognition;feature extraction;image classification;object detection;Haar-like features;boosted cascade;false alarm rate;feature classifiers;hit rate;multi-stage classification;post optimization procedure;rapid object detection;sample face detector;Chromium;Detectors;Face detection;Humans;Object detection;Prototypes;Table lookup;Testing},
	Pages = {I-900-I-903 vol.1},
	Title = {An extended set of Haar-like features for rapid object detection},
	Volume = {1},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ICIP.2002.1038171}}

@inproceedings{zhu2006hogs,
	Abstract = {We integrate the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features to achieve a fast and accurate human detection system. The features used in our system are HoGs of variable-size blocks that capture salient features of humans automatically. Using AdaBoost for feature selection, we identify the appropriate set of blocks, from a large set of possible blocks. In our system, we use the integral image representation and a rejection cascade which significantly speed up the computation. For a 320 Ã— 280 image, the system can process 5 to 30 frames per second depending on the density in which we scan the image, while maintaining an accuracy level similar to existing methods.},
	Author = {Qiang Zhu and Yeh, M.-C. and Kwang-Ting Cheng and Avidan, S.},
	Booktitle = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
	Doi = {10.1109/CVPR.2006.119},
	Issn = {1063-6919},
	Keywords = {Assembly;Clothing;Face detection;Histograms;Humans;Image representation;Laboratories;Object detection;Support vector machine classification;Support vector machines},
	Pages = {1491-1498},
	Title = {Fast Human Detection Using a Cascade of Histograms of Oriented Gradients},
	Volume = {2},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/CVPR.2006.119}}

@inproceedings{rublee2011orb,
	Abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
	Author = {Rublee, E. and Rabaud, V. and Konolige, K. and Bradski, G.},
	Booktitle = {Computer Vision (ICCV), 2011 IEEE International Conference on},
	Doi = {10.1109/ICCV.2011.6126544},
	Issn = {1550-5499},
	Keywords = {computer vision;image matching;object detection;object recognition;tracking;transforms;BRIEF;ORB;SIFT;SURF;binary descriptor;computer vision;feature matching;noise resistance;object detection;object recognition;patch-tracking;smart phone;Boats},
	Month = {Nov},
	Pages = {2564-2571},
	Title = {ORB: An efficient alternative to SIFT or SURF},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ICCV.2011.6126544}}

@misc{pbr,
  Author = {Joe Wilson},
  Year = {2015},
  Title = {PBR In Practice},
  Howpublished = {\url{http://www.marmoset.co/toolbag/learn/pbr-practice}},
  Note = {Last accessed on Mar 25, 2015}
}